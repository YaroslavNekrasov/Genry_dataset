# Genry_dataset

---

### Отчет: Разработка датасета с точки зрения Data Engineer

#### Введение
Как Data Engineer, моя задача заключалась в подготовке данных для дальнейшей работы с ними в аналитических и машинных системах. Я занимался очисткой, структурированием и подготовкой исходных данных для их использования в модели, созданной для анализа текстов и построения рекомендательных систем. В данном отчете я расскажу о процессе обработки и создания датасета **test_data.txt**.

#### Процесс работы

1. **Сбор и извлечение данных**:
   Начальный этап работы заключался в извлечении информации о фильмах. Мы использовали данные из открытых источников, таких как IMDb и TMDb, которые содержат аннотации к фильмам, их названия, годы выпуска и краткие описания. Я проверил, что источники данных достоверны и содержат актуальную информацию.

2. **Очистка данных**:
   Извлеченные данные не всегда были в идеальном виде. Некоторые строки содержали лишние пробелы, теги HTML или другие артефакты, которые нужно было удалить. Я использовал регулярные выражения для очистки текста, а также простые методы обработки, чтобы удалить лишнюю информацию и оставить только полезные для анализа данные.

3. **Структурирование данных**:
   После очистки данных, я приступил к созданию структуры датасета. Для удобства дальнейшей работы с данными, я разделил их на три ключевых элемента:
   - Уникальный идентификатор фильма
   - Название фильма
   - Описание фильма
   
   Структура файла **test_data.txt** была выбрана таким образом, чтобы каждый фильм был представлен одной строкой в формате:  
   `ID ::: Название (Год) ::: Описание`. Это позволило избежать путаницы и упростить обработку данных.

4. **Тестирование и валидация**:
   Важным этапом работы было тестирование созданного датасета. Я проверил, что данные не содержат дублирования, а также что формат файлов соответствует ожидаемому. Каждая строка должна была содержать точное количество элементов: идентификатор, название и описание фильма. Это обеспечило единообразие данных и их удобство для последующего анализа.

#### Технические решения

Для обработки данных я использовал Python и такие библиотеки, как:
- **Pandas** для обработки и структурирования данных.
- **BeautifulSoup** для очистки данных от HTML-тегов.
- **Regular Expressions** для извлечения и удаления ненужных элементов текста.

Кроме того, для эффективного хранения данных использовался текстовый формат, что позволило легко работать с ними в дальнейшем, например, импортировать их в базы данных или передавать в модель машинного обучения.

#### Заключение
Моя работа как Data Engineer заключалась в извлечении, очистке и подготовке данных для их дальнейшего использования. Благодаря созданному датасету с чистыми и структурированными данными, мы обеспечили надежную основу для разработки системы рекомендаций и проведения анализа текстов.

---
